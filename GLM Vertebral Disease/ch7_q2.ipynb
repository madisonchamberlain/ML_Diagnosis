{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch7_q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s0znhQznh-W"
      },
      "source": [
        "## Demonstrate how both the OVA and AVA methods work by predicting the class with the highest probability using binary class logistic regression on the Vertebrae data (eg. DH, SL, or NO). Verify using multi-class logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6cRCRhwnd8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d45e7d92-5a4c-4b8b-d190-206712cc8557"
      },
      "source": [
        "# import drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20ab5xe1nzC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "0f7e79cf-b108-48ae-95f0-ea1fa3d2fc16"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "my_path = '/content/drive/My Drive/column_3C.dat'\n",
        "vert = pd.read_csv(my_path, sep=' ',header=None)\n",
        "vert.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.03</td>\n",
              "      <td>22.55</td>\n",
              "      <td>39.61</td>\n",
              "      <td>40.48</td>\n",
              "      <td>98.67</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>DH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.06</td>\n",
              "      <td>10.06</td>\n",
              "      <td>25.02</td>\n",
              "      <td>29.00</td>\n",
              "      <td>114.41</td>\n",
              "      <td>4.56</td>\n",
              "      <td>DH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68.83</td>\n",
              "      <td>22.22</td>\n",
              "      <td>50.09</td>\n",
              "      <td>46.61</td>\n",
              "      <td>105.99</td>\n",
              "      <td>-3.53</td>\n",
              "      <td>DH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69.30</td>\n",
              "      <td>24.65</td>\n",
              "      <td>44.31</td>\n",
              "      <td>44.64</td>\n",
              "      <td>101.87</td>\n",
              "      <td>11.21</td>\n",
              "      <td>DH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.71</td>\n",
              "      <td>9.65</td>\n",
              "      <td>28.32</td>\n",
              "      <td>40.06</td>\n",
              "      <td>108.17</td>\n",
              "      <td>7.92</td>\n",
              "      <td>DH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0      1      2      3       4      5   6\n",
              "0  63.03  22.55  39.61  40.48   98.67  -0.25  DH\n",
              "1  39.06  10.06  25.02  29.00  114.41   4.56  DH\n",
              "2  68.83  22.22  50.09  46.61  105.99  -3.53  DH\n",
              "3  69.30  24.65  44.31  44.64  101.87  11.21  DH\n",
              "4  49.71   9.65  28.32  40.06  108.17   7.92  DH"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekORv7kzbUd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "50c9cb68-7f43-4be3-b7a2-5437d2795c90"
      },
      "source": [
        "vertDumms=pd.get_dummies(vert.iloc[:,6].astype(str),drop_first=False)\n",
        "vert_dataset = vert.iloc[:,list(range(0,6))]\n",
        "vert_dataset=  pd.concat([vert_dataset,vertDumms],axis=1)\n",
        "vert_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>DH</th>\n",
              "      <th>NO</th>\n",
              "      <th>SL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.03</td>\n",
              "      <td>22.55</td>\n",
              "      <td>39.61</td>\n",
              "      <td>40.48</td>\n",
              "      <td>98.67</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.06</td>\n",
              "      <td>10.06</td>\n",
              "      <td>25.02</td>\n",
              "      <td>29.00</td>\n",
              "      <td>114.41</td>\n",
              "      <td>4.56</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68.83</td>\n",
              "      <td>22.22</td>\n",
              "      <td>50.09</td>\n",
              "      <td>46.61</td>\n",
              "      <td>105.99</td>\n",
              "      <td>-3.53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69.30</td>\n",
              "      <td>24.65</td>\n",
              "      <td>44.31</td>\n",
              "      <td>44.64</td>\n",
              "      <td>101.87</td>\n",
              "      <td>11.21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.71</td>\n",
              "      <td>9.65</td>\n",
              "      <td>28.32</td>\n",
              "      <td>40.06</td>\n",
              "      <td>108.17</td>\n",
              "      <td>7.92</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0      1      2      3       4      5  DH  NO  SL\n",
              "0  63.03  22.55  39.61  40.48   98.67  -0.25   1   0   0\n",
              "1  39.06  10.06  25.02  29.00  114.41   4.56   1   0   0\n",
              "2  68.83  22.22  50.09  46.61  105.99  -3.53   1   0   0\n",
              "3  69.30  24.65  44.31  44.64  101.87  11.21   1   0   0\n",
              "4  49.71   9.65  28.32  40.06  108.17   7.92   1   0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W826u_xNgyTa"
      },
      "source": [
        "# OVA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MsFjNtogWxi"
      },
      "source": [
        "def OVA_method(vert_dataset, test_size):  # creates a dictionary of the \n",
        "\n",
        "  from sklearn.model_selection import train_test_split \n",
        "  import statsmodels.api as sm\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from statistics import mode\n",
        "  import warnings\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  X = vert_dataset.iloc[:,list(range(0,6))]\n",
        "  Y_DH = pd.DataFrame(vert_dataset.loc[:,'DH'])\n",
        "  Y_NO = pd.DataFrame(vert_dataset.loc[:,'NO'])\n",
        "  Y_SL = pd.DataFrame(vert_dataset.loc[:,'SL'])\n",
        "\n",
        "  accuracy_scores = {}\n",
        "  # Y = DH\n",
        "  X_train_DH, X_test_DH, y_train_DH, y_test_DH = train_test_split(X, Y_DH, test_size=test_size) # split the data with the DH row being the Y variable\n",
        "  model_DH = sm.GLM(y_train_DH, X_train_DH,family=sm.families.Binomial()).fit()  # fit the train set to the GLM model \n",
        "  ypred_DH = model_DH.predict(X_test_DH)  # use the model to generate predictions for the test set \n",
        "  predictions_nominal_DH = [ 0 if x < 0.5 else 1 for x in ypred_DH]  #  this gives you the predictions of DH or not DH \n",
        "  DH_yes = predictions_nominal_DH.count(1)  # count how many of the times DH yes appears\n",
        "  probability_DH = DH_yes/(len(predictions_nominal_DH))  # divide the occurances of DH by the number of rows in the DH column \n",
        "  accuracy_scores['DH'] = probability_DH  # add the probability to the dictionary \n",
        " \n",
        " # repead for NO columns and SL column \n",
        " \n",
        "  # Y = NO\n",
        "  X_train_NO, X_test_NO, y_train_NO, y_test_NO = train_test_split(X, Y_NO, test_size=test_size)\n",
        "  model_NO = sm.GLM(y_train_NO, X_train_NO,family=sm.families.Binomial()).fit()\n",
        "  ypred_NO = model_NO.predict(X_test_NO)\n",
        "  predictions_nominal_NO = [ 0 if x < 0.5 else 1 for x in ypred_NO]  #  this gives you the predictions of NO or not NO\n",
        "  NO_yes = predictions_nominal_NO.count(1)\n",
        "  probability_NO = NO_yes/(len(predictions_nominal_NO))\n",
        "  accuracy_scores['NO'] = probability_NO\n",
        "\n",
        "  # Y = SL\n",
        "  X_train_SL, X_test_SL, y_train_SL, y_test_SL = train_test_split(X, Y_SL, test_size=test_size)\n",
        "  model_SL = sm.GLM(y_train_SL, X_train_SL,family=sm.families.Binomial()).fit()\n",
        "  ypred_SL = model_SL.predict(X_test_SL)\n",
        "  predictions_nominal_SL = [ 0 if x < 0.5 else 1 for x in ypred_SL]  #  this gives you the predictions of SL or not SL\n",
        "  SL_yes = predictions_nominal_SL.count(1)\n",
        "  probability_SL = SL_yes/(len(predictions_nominal_SL))\n",
        "  accuracy_scores['SL'] = probability_SL\n",
        " \n",
        "  return(accuracy_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fz4B2SQHoOl"
      },
      "source": [
        "To find the best class and its probability for one run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsN5MWK_Fz98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1e686bc9-0d0a-443a-ce94-052fa83b94e6"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "dictionary = OVA_method(vert_dataset, 0.2)\n",
        "print(\"Each class was found to have the following probability:\")\n",
        "print(dictionary)\n",
        "\n",
        "best_class = max(dictionary, key=dictionary.get)  # to find the best class just get the max probability\n",
        "probability = dictionary[best_class]\n",
        "print(\"\\nThe best class using OVA was\", best_class, \"with a probability of\", round(probability,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Each class was found to have the following probability:\n",
            "{'DH': 0.1774193548387097, 'NO': 0.3548387096774194, 'SL': 0.4838709677419355}\n",
            "\n",
            "The best class using OVA was SL with a probability of 0.4839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9s3uv_vg1dF"
      },
      "source": [
        "# AVA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2_7wOvTCxRi"
      },
      "source": [
        "def AVA_method(vert, test_size):  \n",
        "  from sklearn.model_selection import train_test_split \n",
        "  import statsmodels.api as sm\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from statistics import mode\n",
        "  import warnings\n",
        "  warnings.filterwarnings('ignore')\n",
        "\n",
        "  #Xs and Ys for each of the three scenarios\n",
        "  # predicting DH = yes, given DH and NO\n",
        "  vert_no_SL = vert[vert.SL != 1]\n",
        "  X_no_SL = vert_no_SL.iloc[:,list(range(0,6))]\n",
        "  Y_DH_no_SL = pd.DataFrame(vert_no_SL.loc[:,'DH'])\n",
        "\n",
        "  # predicting DH = yes, given DH and SL\n",
        "  vert_no_NO = vert[vert.NO != 1]\n",
        "  X_no_NO = vert_no_NO.iloc[:,list(range(0,6))]\n",
        "  Y_DH_no_NO = pd.DataFrame(vert_no_NO.loc[:,'DH'])\n",
        "\n",
        "  # predicting NO = yes, given SL and NO\n",
        "  vert_no_DH = vert[vert.DH != 1]\n",
        "  X_no_DH = vert_no_DH.iloc[:,list(range(0,6))]\n",
        "  Y_NO_no_DH = pd.DataFrame(vert_no_DH.loc[:,'NO'])\n",
        "\n",
        "  accuracy_scores = [] # this time I'm using lists rather than a dictionary because I'm counting which class wins the most \n",
        "  # no SL, Y = DH\n",
        "  X_train_DH, X_test_DH, y_train_DH, y_test_DH = train_test_split(X_no_SL, Y_DH_no_SL, test_size=test_size)  # split the data with the appropriate X and Y\n",
        "  model_DH = sm.GLM(y_train_DH, X_train_DH,family=sm.families.Binomial()).fit()  # generate the GLM model fit to the train set \n",
        "  ypred_DH = model_DH.predict(X_test_DH)  # generate a prediction with the test set \n",
        "  predictions_nominal_DH = [ 0 if x < 0.5 else 1 for x in ypred_DH]  #  this gives you the predictions of DH or not DH \n",
        "  DH_yes = predictions_nominal_DH.count(1)  # count how many times DH appears given DH or NO\n",
        "  probability_DH = DH_yes/(len(predictions_nominal_DH))  # find the probability of DH being predicted\n",
        "  if probability_DH >= 0.5:  # If DH is more likely... DH wins \n",
        "    answer = ['DH', probability_DH]  # add DH and the probability of getting DH to the list\n",
        "    accuracy_scores.append(answer)  # add this to the list\n",
        "  else:   # If NO is more likely... NO wins \n",
        "    answer = ['NO', 1 - probability_DH]  # add NO and the probability of getting NO to the list \n",
        "    accuracy_scores.append(answer)\n",
        "\n",
        "  # repeat for the rest of the options =...\n",
        "  # no NO, Y = DH\n",
        "  X_train_DH2, X_test_DH2, y_train_DH2, y_test_DH2 = train_test_split(X_no_NO, Y_DH_no_NO, test_size=test_size)\n",
        "  model_DH2 = sm.GLM(y_train_DH2, X_train_DH2,family=sm.families.Binomial()).fit()\n",
        "  ypred_DH2 = model_DH2.predict(X_test_DH2)\n",
        "  predictions_nominal_DH2 = [ 0 if x < 0.5 else 1 for x in ypred_DH2]  #  this gives you the predictions of DH or not DH \n",
        "  DH2_yes = predictions_nominal_DH2.count(1)\n",
        "  probability_DH2 = DH2_yes/(len(predictions_nominal_DH2))\n",
        "  probability_NO = 1 - probability_DH2\n",
        "  if probability_DH2 >= 0.5:  # DH wins \n",
        "    answer = ['DH', probability_DH2]\n",
        "    accuracy_scores.append(answer)\n",
        "  else:   # SL wins \n",
        "    answer = ['SL', 1 - probability_DH2]\n",
        "    accuracy_scores.append(answer)\n",
        "\n",
        "  # no DH, Y = NO\n",
        "  X_train_NO, X_test_NO, y_train_NO, y_test_NO = train_test_split(X_no_DH, Y_NO_no_DH, test_size=test_size)\n",
        "  model_NO = sm.GLM(y_train_NO, X_train_NO,family=sm.families.Binomial()).fit()\n",
        "  ypred_NO = model_NO.predict(X_test_NO)\n",
        "  predictions_nominal_NO = [ 0 if x < 0.5 else 1 for x in ypred_NO]  #  this gives you the predictions of DH or not DH \n",
        "  NO_yes = predictions_nominal_NO.count(1)\n",
        "  probability_NO = NO_yes/(len(predictions_nominal_NO))\n",
        "  if probability_NO >= 0.5:  # NO wins \n",
        "    answer = ['NO', probability_NO]\n",
        "    accuracy_scores.append(answer)\n",
        "  else:   # SL wins \n",
        "    answer = ['SL', 1 - probability_NO]\n",
        "    accuracy_scores.append(answer)\n",
        " \n",
        "  return(accuracy_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOllXN11QiBi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "216afbc8-8e66-4a03-c028-154142de42d0"
      },
      "source": [
        "# If this has a PerfectSeperationError just run it again and it will work \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "options = AVA_method(vert_dataset, 0.2)\n",
        "# just to see how likely each winning class was to be chosen I printed the list\n",
        "print(\"Each class was found to have the following probability:\")\n",
        "print(options)\n",
        "\n",
        "just_classes = []\n",
        "for item in options:\n",
        "  just_classes.append(item[0]) # create a new list of the classes that won their individual battels \n",
        "# then I print which class appeared most in the list \n",
        "print(\"\\nThe best class using AVA was found to be \", mode(just_classes))  # whichever one wins the most is the overall AVA winner "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Each class was found to have the following probability:\n",
            "[['NO', 0.6875], ['SL', 0.6666666666666667], ['SL', 0.54]]\n",
            "\n",
            "The best class using AVA was found to be  SL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC4lQNpChvf3"
      },
      "source": [
        "Comparison between the two models built:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Hy1Lh5h5jn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d6c319e0-ae90-4a26-8d1b-525b15e68d3f"
      },
      "source": [
        "# Here I wanted to test the models I bulit against the multi class function \n",
        "from sklearn.model_selection import train_test_split \n",
        "import statsmodels.api as sm\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "X = vert_dataset.iloc[:,list(range(0,6))]\n",
        "Y_SL = pd.DataFrame(vert_dataset.loc[:,'SL'])\n",
        "le = preprocessing.LabelEncoder()\n",
        "vert.iloc[:,6] = le.fit_transform(vert.iloc[:,6])\n",
        "X = vert.iloc[:,list(range(0,6))]\n",
        "Y = vert.iloc[:,6]\n",
        "\n",
        "# Here I am generate predictions with the binomial model using the winning class from AVA/OVA\n",
        "X_train_SL, X_test_SL, y_train_SL, y_test_SL = train_test_split(X, Y_SL, test_size=0.2)\n",
        "model_SL = sm.GLM(y_train_SL, X_train_SL,family=sm.families.Binomial()).fit()\n",
        "prediction_binary = model_SL.predict(X)  # I am using the model_SL model which I generated above to predict SL or not SL\n",
        "predictions_nominal_SL = [ 0 if x < 0.5 else 2 for x in prediction_binary] # predict 2 for 'SL' or 0 for not SL \n",
        "\n",
        "# Here I used the multi class model to predict \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)  # split the data\n",
        "model = LogisticRegression()  # the default for the LogisticRegression() call is multi class\n",
        "model.fit(X_train, y_train)  # fit the train set to the multi class model\n",
        "prediction_multi_class = model.predict(X)  # generate predictions with this model for all of X to compare\n",
        "\n",
        "accuracy1 = accuracy_score(Y,predictions_nominal_SL)\n",
        "print(\"The prediction accuracy for the binomial model on the entire data set:\")\n",
        "print(accuracy1)\n",
        "accuracy2 = accuracy_score(Y,prediction_multi_class)\n",
        "print(\"\\nThe prediction accuracy for the multiclass model:\")\n",
        "print(accuracy2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction accuracy for the binomial model on the entire data set:\n",
            "0.6580645161290323\n",
            "\n",
            "The prediction accuracy for the multiclass model:\n",
            "0.8709677419354839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiL5d45isZ4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "f9008996-e8b8-45a7-eb37-30bfd1ab4993"
      },
      "source": [
        "# If you want to check the predictions/real y value for a specific row...\n",
        "\n",
        "prediction_binary = predictions_nominal_SL[5]\n",
        "prediction_multi_class1 = prediction_multi_class[5]\n",
        "real_value_of_Y = Y[5]\n",
        "\n",
        "print(\"\\nThe prediction generated using the binary model:\")\n",
        "print(prediction_binary)\n",
        "print(\"\\nThe prediction generated using the multi class model:\")\n",
        "print(prediction_multi_class1)\n",
        "print(\"\\nThe true value of Y:\")\n",
        "print(real_value_of_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The prediction generated using the binary model:\n",
            "0\n",
            "\n",
            "The prediction generated using the multi class model:\n",
            "1\n",
            "\n",
            "The true value of Y:\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}